# Flutter_Chatbot

A RAG (Retrieval-Augmented Generation) based chatbot for Flutter documentation, powered by OpenAI and Google Cloud Platform.

## Tech Stack and Structure

### Frameworks and Services

- **Frontend Framework**: React
- **Backend (FaaS)**: Google Cloud Functions
- **Data Collection**: Google Cloud Scheduler
- **Data Storage & Indexing (RAG Core)**: Google Vertex AI Vector Search
- **AI / Language Model**: OpenAI (GPT-4)
- **Source Control & Collaboration**: GitHub
- **Data Source**: Flutter GitHub Repository (via GitHub API)

### Project Structure

```
/Flutter_Chatbot/
â”œâ”€â”€ .github/                  # GitHub Actions workflows
â”œâ”€â”€ frontend/                 # React application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/       # React components
â”‚   â”‚   â”œâ”€â”€ services/         # API services
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ public/
â”‚
â”œâ”€â”€ functions/                # Google Cloud Functions
â”‚   â”œâ”€â”€ crawler.js            # Web crawler function
â”‚   â”œâ”€â”€ llm.js                # LLM integration (OpenAI)
â”‚   â”œâ”€â”€ search.js             # Vector search function
â”‚   â”œâ”€â”€ syncMissingFiles.js   # GitHub sync utilities
â”‚   â”œâ”€â”€ check-statefulwidget.js
â”‚   â”œâ”€â”€ compare-sync.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ README.md
```


## Main Processes

### Process 1: Background Data Collection (Populating the Vector Database)

This process runs on a schedule (e.g., weekly) via Google Cloud Scheduler and doesn't involve user interaction.

**Flow:**

1. **â° Google Cloud Scheduler** â†’ Triggers the crawler function
2. **ğŸ¤– Crawler Cloud Function** ([crawler.js](functions/crawler.js))
   - Fetches Flutter documentation from GitHub API
   - Processes markdown files and code examples
   - Generates vector embeddings using OpenAI's embedding model
3. **ğŸ“š Vertex AI Vector Search** â†’ Stores embeddings for fast similarity search

**Key Features:**
- Automatic synchronization with Flutter repository
- Batch processing with progress tracking
- Incremental updates to avoid redundant processing

### Process 2: Real-Time Question Answering (RAG Pipeline)

This happens instantly when a user asks a question in the chat interface.

**Flow:**

1. **ğŸ‘¨â€ğŸ’» User** â†’ Asks a question in the React app
2. **ğŸŒ React App** â†’ Sends the question to the backend
3. **ğŸ” Search Function** ([search.js](functions/search.js))
   - Converts the question into a vector embedding
   - Queries Vertex AI Vector Search for relevant documents
   - Returns the most similar documentation chunks
4. **ğŸ§  LLM Function** ([llm.js](functions/llm.js))
   - Receives user question + relevant context documents
   - Sends to OpenAI GPT-4 for answer generation
   - Formats and returns the final answer
5. **â¬…ï¸ Response** â†’ Displayed to the user in the chat interface

**Key Features:**
- Semantic search for accurate document retrieval
- Context-aware answer generation
- Real-time response streaming

## Setup and Deployment

### Prerequisites

- Node.js 18+
- Google Cloud Platform account
- OpenAI API key
- GitHub personal access token (for data collection)

### Environment Variables

Create a `.env` file in the `functions/` directory:

```env
OPENAI_API_KEY=your_openai_api_key
GITHUB_TOKEN=your_github_token
GCP_PROJECT_ID=your_gcp_project_id
VECTOR_SEARCH_INDEX_ENDPOINT=your_vector_search_endpoint
```

### Local Development

```bash
# Install frontend dependencies
cd frontend
npm install
npm start

# Install backend dependencies
cd functions
npm install

# Deploy functions to GCP
firebase deploy --only functions
```

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

This project is open source and available under the MIT License.

